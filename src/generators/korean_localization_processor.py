"""
Korean Localization Processor for AWS SAA Study Materials
ì½˜í…ì¸  í˜„ì§€í™” í”„ë¡œì„¸ì„œ - í•œêµ­ì–´ ì½˜í…ì¸  ìƒì„± ë° ìë™ í•œì˜ ë³‘ê¸°
"""

import re
from typing import Dict, List, Optional, Set
from pathlib import Path

from src.generators.korean_term_dictionary import (
    get_korean_term_dictionary,
    KoreanTermDictionary,
    TermCategory
)
from src.daily_topics import DAILY_TOPICS


class KoreanLocalizationProcessor:
    """í•œêµ­ì–´ í˜„ì§€í™” í”„ë¡œì„¸ì„œ"""
    
    def __init__(self):
        self.dictionary = get_korean_term_dictionary()
        self._processed_terms: Set[str] = set()
    
    def localize_content(self, content: str, day_number: Optional[int] = None) -> str:
        """ì½˜í…ì¸  í˜„ì§€í™” - ì˜ì–´ ê¸°ìˆ  ìš©ì–´ì— í•œêµ­ì–´ ë²ˆì—­ ìë™ ì¶”ê°€
        
        Args:
            content: ì›ë³¸ ì½˜í…ì¸ 
            day_number: ì¼ì°¨ ë²ˆí˜¸ (ì„ íƒì‚¬í•­, í•´ë‹¹ ì¼ì°¨ ê´€ë ¨ ìš©ì–´ ìš°ì„  ì²˜ë¦¬)
            
        Returns:
            í˜„ì§€í™”ëœ ì½˜í…ì¸ 
        """
        # ì²˜ë¦¬ëœ ìš©ì–´ ì´ˆê¸°í™”
        self._processed_terms.clear()
        
        # í•´ë‹¹ ì¼ì°¨ ê´€ë ¨ ìš©ì–´ ìš°ì„  ì²˜ë¦¬
        if day_number:
            day_terms = self.dictionary.search_by_day(day_number)
            for term in day_terms:
                content = self._apply_bilingual_notation_for_term(content, term.english)
        
        # AWS ì„œë¹„ìŠ¤ ìš©ì–´ ì²˜ë¦¬
        aws_services = self.dictionary.get_all_aws_services()
        for service in aws_services:
            content = self._apply_bilingual_notation_for_term(content, service.english)
        
        # ê¸°íƒ€ ì¹´í…Œê³ ë¦¬ ìš©ì–´ ì²˜ë¦¬
        for category in [TermCategory.ARCHITECTURE, TermCategory.NETWORKING, 
                        TermCategory.SECURITY, TermCategory.DATABASE,
                        TermCategory.STORAGE, TermCategory.COMPUTE]:
            terms = self.dictionary.search_by_category(category)
            for term in terms:
                content = self._apply_bilingual_notation_for_term(content, term.english)
        
        return content
    
    def _apply_bilingual_notation_for_term(self, content: str, english_term: str) -> str:
        """íŠ¹ì • ìš©ì–´ì— ëŒ€í•´ í•œì˜ ë³‘ê¸° ì ìš©
        
        Args:
            content: ì½˜í…ì¸ 
            english_term: ì˜ì–´ ìš©ì–´
            
        Returns:
            í•œì˜ ë³‘ê¸°ê°€ ì ìš©ëœ ì½˜í…ì¸ 
        """
        # ì´ë¯¸ ì²˜ë¦¬ëœ ìš©ì–´ëŠ” ìŠ¤í‚µ
        if english_term in self._processed_terms:
            return content
        
        term = self.dictionary.get_term(english_term)
        if not term:
            return content
        
        # í•œì˜ ë³‘ê¸° í‘œê¸° ìƒì„±
        bilingual = self.dictionary.get_bilingual_notation(english_term)
        
        # ì´ë¯¸ í•œì˜ ë³‘ê¸°ê°€ ìˆëŠ” ê²½ìš° ìŠ¤í‚µ
        if bilingual in content:
            self._processed_terms.add(english_term)
            return content
        
        # ì˜ì–´ ìš©ì–´ë§Œ ìˆëŠ” ê²½ìš° í•œì˜ ë³‘ê¸°ë¡œ êµì²´
        # ë‹¨ì–´ ê²½ê³„ë¥¼ ê³ ë ¤í•˜ì—¬ ì •í™•í•œ ë§¤ì¹­
        pattern = r'\b' + re.escape(english_term) + r'\b'
        
        # ì²« ë²ˆì§¸ ë°œê²¬ëœ ìš©ì–´ë§Œ êµì²´ (ë¬¸ì„œ ë‚´ ì²« ë“±ì¥ ì‹œì—ë§Œ ë³‘ê¸°)
        content = re.sub(pattern, bilingual, content, count=1)
        
        self._processed_terms.add(english_term)
        return content
    
    def apply_bilingual_notation(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì— ìë™ìœ¼ë¡œ í•œì˜ ë³‘ê¸° ì ìš©
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            
        Returns:
            í•œì˜ ë³‘ê¸°ê°€ ì ìš©ëœ í…ìŠ¤íŠ¸
        """
        return self.localize_content(text)
    
    def validate_term_consistency(self, content: str) -> List[Dict[str, str]]:
        """ì½˜í…ì¸  ë‚´ ìš©ì–´ ì¼ê´€ì„± ê²€ì¦
        
        Args:
            content: ê²€ì¦í•  ì½˜í…ì¸ 
            
        Returns:
            ë¶ˆì¼ì¹˜ í•­ëª© ë¦¬ìŠ¤íŠ¸ [{"term": "...", "issue": "...", "suggestion": "..."}, ...]
        """
        issues = []
        
        # ìš©ì–´ ì‚¬ì „ì˜ ëª¨ë“  ì˜ì–´ ìš©ì–´ í™•ì¸
        for english_key, term in self.dictionary.terms.items():
            if english_key == term.english.lower():
                # ì˜ì–´ ìš©ì–´ê°€ ì½˜í…ì¸ ì— ìˆëŠ”ì§€ í™•ì¸
                if term.english in content:
                    bilingual = self.dictionary.get_bilingual_notation(term.english)
                    
                    # í•œì˜ ë³‘ê¸°ê°€ ì—†ëŠ” ê²½ìš°
                    if bilingual not in content and term.korean not in content:
                        issues.append({
                            "term": term.english,
                            "issue": "í•œêµ­ì–´ ë²ˆì—­ ëˆ„ë½",
                            "suggestion": f"'{term.english}'ë¥¼ '{bilingual}'ë¡œ ë³€ê²½"
                        })
                    
                    # í•œêµ­ì–´ë§Œ ìˆê³  ì˜ì–´ê°€ ì—†ëŠ” ê²½ìš°
                    elif term.korean in content and f"({term.english})" not in content:
                        # ì²« ë“±ì¥ ì‹œì—ëŠ” ë³‘ê¸° í•„ìš”
                        first_occurrence = content.find(term.korean)
                        if first_occurrence != -1:
                            # ê´„í˜¸ ì•ˆì— ì˜ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
                            next_paren = content.find("(", first_occurrence)
                            if next_paren == -1 or next_paren > first_occurrence + len(term.korean) + 5:
                                issues.append({
                                    "term": term.korean,
                                    "issue": "ì˜ì–´ ì›ë¬¸ ëˆ„ë½",
                                    "suggestion": f"'{term.korean}'ë¥¼ '{bilingual}'ë¡œ ë³€ê²½"
                                })
        
        return issues
    
    def get_localized_template_vars(self, day_number: int) -> Dict[str, str]:
        """ì¼ì°¨ë³„ í˜„ì§€í™”ëœ í…œí”Œë¦¿ ë³€ìˆ˜ ìƒì„±
        
        Args:
            day_number: ì¼ì°¨ ë²ˆí˜¸ (1-28)
            
        Returns:
            í˜„ì§€í™”ëœ í…œí”Œë¦¿ ë³€ìˆ˜ ë”•ì…”ë„ˆë¦¬
        """
        if day_number not in DAILY_TOPICS:
            raise ValueError(f"Invalid day number: {day_number}")
        
        config = DAILY_TOPICS[day_number]
        localized_vars = {}
        
        # ì£¼ìš” ì„œë¹„ìŠ¤ í˜„ì§€í™”
        primary_services = config["primary_services"]
        localized_services = []
        for service in primary_services:
            term = self.dictionary.get_term(service)
            if term:
                localized_services.append(self.dictionary.get_bilingual_notation(service))
            else:
                localized_services.append(service)
        
        localized_vars["primary_services_localized"] = ", ".join(localized_services)
        localized_vars["primary_service_localized"] = localized_services[0] if localized_services else ""
        
        # ì œëª© í˜„ì§€í™” (ì´ë¯¸ í•œêµ­ì–´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        localized_vars["title_localized"] = config["title"]
        
        # ì‚¬ë¡€ ì—°êµ¬ ì´ˆì  í˜„ì§€í™”
        localized_vars["case_study_focus_localized"] = config["case_study_focus"]
        
        # ë‚œì´ë„ í˜„ì§€í™”
        difficulty_map = {
            "basic": "ê¸°ì´ˆ",
            "intermediate": "ì¤‘ê¸‰",
            "advanced": "ê³ ê¸‰"
        }
        localized_vars["difficulty_localized"] = difficulty_map.get(config["difficulty"], config["difficulty"])
        
        return localized_vars
    
    def localize_aws_service_name(self, service_name: str) -> str:
        """AWS ì„œë¹„ìŠ¤ëª… í˜„ì§€í™”
        
        Args:
            service_name: AWS ì„œë¹„ìŠ¤ ì˜ì–´ëª…
            
        Returns:
            í•œì˜ ë³‘ê¸° ì„œë¹„ìŠ¤ëª…
        """
        return self.dictionary.get_bilingual_notation(service_name)
    
    def get_korean_only(self, english_term: str) -> str:
        """ì˜ì–´ ìš©ì–´ì˜ í•œêµ­ì–´ ë²ˆì—­ë§Œ ë°˜í™˜
        
        Args:
            english_term: ì˜ì–´ ìš©ì–´
            
        Returns:
            í•œêµ­ì–´ ë²ˆì—­
        """
        return self.dictionary.get_korean_term(english_term)
    
    def get_english_only(self, korean_term: str) -> str:
        """í•œêµ­ì–´ ìš©ì–´ì˜ ì˜ì–´ ì›ë¬¸ë§Œ ë°˜í™˜
        
        Args:
            korean_term: í•œêµ­ì–´ ìš©ì–´
            
        Returns:
            ì˜ì–´ ì›ë¬¸
        """
        return self.dictionary.get_english_term(korean_term)
    
    def generate_glossary_section(self, day_number: Optional[int] = None) -> str:
        """ìš©ì–´ì§‘ ì„¹ì…˜ ìƒì„±
        
        Args:
            day_number: ì¼ì°¨ ë²ˆí˜¸ (ì„ íƒì‚¬í•­, í•´ë‹¹ ì¼ì°¨ ê´€ë ¨ ìš©ì–´ë§Œ í¬í•¨)
            
        Returns:
            ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ìš©ì–´ì§‘ ì„¹ì…˜
        """
        glossary = ["## ğŸ“š ìš©ì–´ì§‘\n"]
        
        if day_number:
            terms = self.dictionary.search_by_day(day_number)
            glossary.append(f"### Day {day_number} ê´€ë ¨ ìš©ì–´\n")
        else:
            terms = list(set(self.dictionary.terms.values()))
            glossary.append("### ì „ì²´ ìš©ì–´\n")
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
        terms_by_category = {}
        for term in terms:
            if term.category not in terms_by_category:
                terms_by_category[term.category] = []
            terms_by_category[term.category].append(term)
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¶œë ¥
        category_names = {
            TermCategory.AWS_SERVICE: "AWS ì„œë¹„ìŠ¤",
            TermCategory.ARCHITECTURE: "ì•„í‚¤í…ì²˜",
            TermCategory.NETWORKING: "ë„¤íŠ¸ì›Œí‚¹",
            TermCategory.SECURITY: "ë³´ì•ˆ",
            TermCategory.DATABASE: "ë°ì´í„°ë² ì´ìŠ¤",
            TermCategory.STORAGE: "ìŠ¤í† ë¦¬ì§€",
            TermCategory.COMPUTE: "ì»´í“¨íŒ…",
            TermCategory.MONITORING: "ëª¨ë‹ˆí„°ë§",
            TermCategory.GENERAL: "ì¼ë°˜"
        }
        
        for category, category_terms in sorted(terms_by_category.items(), key=lambda x: x[0].value):
            glossary.append(f"\n#### {category_names[category]}\n")
            for term in sorted(category_terms, key=lambda t: t.korean):
                if term.abbreviation:
                    glossary.append(f"- **{term.korean}** ({term.english}, {term.abbreviation})")
                else:
                    glossary.append(f"- **{term.korean}** ({term.english})")
                if term.description:
                    glossary.append(f"  - {term.description}")
                glossary.append("")
        
        return "\n".join(glossary)
    
    def create_localization_report(self, content: str, day_number: Optional[int] = None) -> Dict:
        """í˜„ì§€í™” ë³´ê³ ì„œ ìƒì„±
        
        Args:
            content: ë¶„ì„í•  ì½˜í…ì¸ 
            day_number: ì¼ì°¨ ë²ˆí˜¸ (ì„ íƒì‚¬í•­)
            
        Returns:
            í˜„ì§€í™” í†µê³„ ë° ì´ìŠˆ ë³´ê³ ì„œ
        """
        report = {
            "day_number": day_number,
            "total_terms_in_dictionary": len(set(self.dictionary.terms.values())),
            "terms_found_in_content": 0,
            "terms_with_bilingual_notation": 0,
            "terms_without_bilingual_notation": 0,
            "consistency_issues": [],
            "recommendations": []
        }
        
        # ì½˜í…ì¸ ì—ì„œ ë°œê²¬ëœ ìš©ì–´ ì¹´ìš´íŠ¸
        found_terms = []
        for english_key, term in self.dictionary.terms.items():
            if english_key == term.english.lower():
                if term.english in content or term.korean in content:
                    found_terms.append(term)
                    report["terms_found_in_content"] += 1
                    
                    # í•œì˜ ë³‘ê¸° ì—¬ë¶€ í™•ì¸
                    bilingual = self.dictionary.get_bilingual_notation(term.english)
                    if bilingual in content:
                        report["terms_with_bilingual_notation"] += 1
                    else:
                        report["terms_without_bilingual_notation"] += 1
        
        # ì¼ê´€ì„± ì´ìŠˆ í™•ì¸
        report["consistency_issues"] = self.validate_term_consistency(content)
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if report["terms_without_bilingual_notation"] > 0:
            report["recommendations"].append(
                f"{report['terms_without_bilingual_notation']}ê°œì˜ ìš©ì–´ì— í•œì˜ ë³‘ê¸°ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            )
        
        if len(report["consistency_issues"]) > 0:
            report["recommendations"].append(
                f"{len(report['consistency_issues'])}ê°œì˜ ìš©ì–´ ì¼ê´€ì„± ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤."
            )
        
        if report["terms_found_in_content"] == 0:
            report["recommendations"].append(
                "ì½˜í…ì¸ ì—ì„œ ìš©ì–´ ì‚¬ì „ì˜ ìš©ì–´ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì½˜í…ì¸ ë¥¼ ê²€í† í•´ì£¼ì„¸ìš”."
            )
        
        return report


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_processor_instance = None


def get_korean_localization_processor() -> KoreanLocalizationProcessor:
    """í•œêµ­ì–´ í˜„ì§€í™” í”„ë¡œì„¸ì„œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _processor_instance
    if _processor_instance is None:
        _processor_instance = KoreanLocalizationProcessor()
    return _processor_instance


# CLI ì‹¤í–‰ì„ ìœ„í•œ ë©”ì¸ í•¨ìˆ˜
def main():
    """CLI ì‹¤í–‰ - ì½˜í…ì¸  í˜„ì§€í™” í…ŒìŠ¤íŠ¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Korean Localization Processor for AWS SAA")
    parser.add_argument("--file", type=str, help="File to localize")
    parser.add_argument("--day", type=int, help="Day number (1-28) for context-aware localization")
    parser.add_argument("--validate", action="store_true", help="Validate term consistency")
    parser.add_argument("--report", action="store_true", help="Generate localization report")
    parser.add_argument("--glossary", action="store_true", help="Generate glossary section")
    parser.add_argument("--output", type=str, help="Output file path")
    
    args = parser.parse_args()
    
    processor = get_korean_localization_processor()
    
    if args.file:
        file_path = Path(args.file)
        if not file_path.exists():
            print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.file}")
            return
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        if args.validate:
            # ìš©ì–´ ì¼ê´€ì„± ê²€ì¦
            issues = processor.validate_term_consistency(content)
            print(f"\nìš©ì–´ ì¼ê´€ì„± ê²€ì¦ ê²°ê³¼: {len(issues)}ê°œ ì´ìŠˆ ë°œê²¬\n")
            for issue in issues:
                print(f"  ìš©ì–´: {issue['term']}")
                print(f"  ë¬¸ì œ: {issue['issue']}")
                print(f"  ì œì•ˆ: {issue['suggestion']}\n")
        
        elif args.report:
            # í˜„ì§€í™” ë³´ê³ ì„œ ìƒì„±
            report = processor.create_localization_report(content, args.day)
            print("\ní˜„ì§€í™” ë³´ê³ ì„œ:")
            print(f"  ì¼ì°¨: {report['day_number']}")
            print(f"  ì‚¬ì „ ì´ ìš©ì–´ ìˆ˜: {report['total_terms_in_dictionary']}")
            print(f"  ì½˜í…ì¸ ì—ì„œ ë°œê²¬ëœ ìš©ì–´: {report['terms_found_in_content']}")
            print(f"  í•œì˜ ë³‘ê¸° ì ìš©ëœ ìš©ì–´: {report['terms_with_bilingual_notation']}")
            print(f"  í•œì˜ ë³‘ê¸° ë¯¸ì ìš© ìš©ì–´: {report['terms_without_bilingual_notation']}")
            print(f"  ì¼ê´€ì„± ì´ìŠˆ: {len(report['consistency_issues'])}")
            print("\nê¶Œì¥ì‚¬í•­:")
            for rec in report['recommendations']:
                print(f"  - {rec}")
        
        else:
            # ì½˜í…ì¸  í˜„ì§€í™”
            localized = processor.localize_content(content, args.day)
            
            if args.output:
                output_path = Path(args.output)
                output_path.parent.mkdir(parents=True, exist_ok=True)
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(localized)
                print(f"í˜„ì§€í™”ëœ ì½˜í…ì¸ ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {args.output}")
            else:
                print("\ní˜„ì§€í™”ëœ ì½˜í…ì¸ :")
                print(localized)
    
    elif args.glossary:
        # ìš©ì–´ì§‘ ìƒì„±
        glossary = processor.generate_glossary_section(args.day)
        
        if args.output:
            output_path = Path(args.output)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(glossary)
            print(f"ìš©ì–´ì§‘ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {args.output}")
        else:
            print(glossary)
    
    else:
        print("ì‚¬ìš©ë²•: python korean_localization_processor.py --file FILE [OPTIONS]")
        print("\nì˜µì…˜:")
        print("  --file FILE         í˜„ì§€í™”í•  íŒŒì¼")
        print("  --day DAY           ì¼ì°¨ ë²ˆí˜¸ (1-28)")
        print("  --validate          ìš©ì–´ ì¼ê´€ì„± ê²€ì¦")
        print("  --report            í˜„ì§€í™” ë³´ê³ ì„œ ìƒì„±")
        print("  --glossary          ìš©ì–´ì§‘ ìƒì„±")
        print("  --output FILE       ì¶œë ¥ íŒŒì¼ ê²½ë¡œ")
        print("\nì˜ˆì‹œ:")
        print("  python korean_localization_processor.py --file case-study.md --day 1")
        print("  python korean_localization_processor.py --file case-study.md --validate")
        print("  python korean_localization_processor.py --glossary --day 1 --output glossary.md")


if __name__ == "__main__":
    main()
